{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:36:45.433031Z",
     "start_time": "2025-05-06T16:36:44.680753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "from sac import SACAgent\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "91a5473517fb5b9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T17:01:20.538602Z",
     "start_time": "2025-05-06T17:00:24.611582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "env = gym.make(\"Pendulum-v1\")\n",
    "agent = SACAgent(env)\n",
    "\n",
    "for episode in range(200):\n",
    "    state = env.reset()\n",
    "    if isinstance(state, tuple):  # Gym >= 0.26 returns (obs, info)\n",
    "        state = state[0]\n",
    "    episode_reward = 0\n",
    "\n",
    "    for t in range(1000):\n",
    "        action = agent.select_action(state)\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        mask = 1 if t == env._max_episode_steps else float(not done)\n",
    "        agent.replay_buffer.add(state, action, reward, next_state, mask)\n",
    "        state = next_state\n",
    "        agent.train()\n",
    "        episode_reward += reward\n",
    "        if done:\n",
    "            print(t)\n",
    "            break\n",
    "\n",
    "    print(f\"Episode {episode} | Reward: {episode_reward:.2f}\")"
   ],
   "id": "d66c3f3ab240a3eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 | Reward: -8076.21\n",
      "Episode 1 | Reward: -7081.31\n",
      "Episode 2 | Reward: -4776.22\n",
      "Episode 3 | Reward: -1693.07\n",
      "Episode 4 | Reward: -255.27\n",
      "Episode 5 | Reward: -337.58\n",
      "Episode 6 | Reward: -125.18\n",
      "Episode 7 | Reward: -327.67\n",
      "Episode 8 | Reward: -5.62\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[75], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m agent\u001B[38;5;241m.\u001B[39mreplay_buffer\u001B[38;5;241m.\u001B[39madd(state, action, reward, next_state, mask)\n\u001B[1;32m     16\u001B[0m state \u001B[38;5;241m=\u001B[39m next_state\n\u001B[0;32m---> 17\u001B[0m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m episode_reward \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m reward\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m done:\n",
      "File \u001B[0;32m~/Desktop/EPFL/ee568-rl/rl_project/sac.py:136\u001B[0m, in \u001B[0;36mSACAgent.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    133\u001B[0m critic_loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mmse_loss(curr_q1, target) \u001B[38;5;241m+\u001B[39m F\u001B[38;5;241m.\u001B[39mmse_loss(curr_q2, target)\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcritic_opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m--> 136\u001B[0m \u001B[43mcritic_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    137\u001B[0m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcritic\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;241m1.0\u001B[39m)\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcritic_opt\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    625\u001B[0m     )\n\u001B[0;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 75
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
